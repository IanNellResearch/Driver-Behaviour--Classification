import cv2
import csv
import numpy as np
from collections import deque
from sklearn.linear_model import RANSACRegressor
from ultralytics import YOLO

# ---------------- Global Constants ---------------- #
OFF_CENTRE_THRESHOLD = 40  # Max allowed deviation from lane centre (pixels)
LATERAL_MOVEMENT_THRESHOLD = 0.3  # Threshold for average lateral drift
IMPAIRED_MOVEMENT_THRESHOLD = 0.6  # Threshold for identifying erratic behaviour
LATERAL_HISTORY_LENGTH = 60  # Number of frames to track lateral movement
SIGN_CHANGE_LATCH_THRESHOLD = 3  # Sign changes required to flag oscillation

# Class IDs of interest (from YOLO model)
classes_of_interest = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorbike', 7: 'truck'}

# ---------------- Initialisation ---------------- #
object_tracks = {}
model = YOLO('yolov8n.pt')

# Previous frame lane data (for temporal smoothing)
previous_left_lane = None
previous_right_lane = None
previous_lane_centre_fit = None

def detect_lanes(frame, vehicle_boxes):
    """
    Detects left, right, and centre lanes using edge detection and RANSAC regression.
    Masks vehicle boxes and performs smoothing using previous frames.
    """
    global previous_left_lane, previous_right_lane, previous_lane_centre_fit

    # Preprocessing
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    adaptive_thresh = cv2.adaptiveThreshold(
        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
    )
    edges = cv2.Canny(adaptive_thresh, 30, 100)

    height, width = frame.shape[:2]

    # Define and apply region of interest (ROI) mask
    mask = np.zeros_like(edges)
    roi = np.array([[(400, 800), (850, 560), (1000, 560), (1380, 800)]], dtype=np.int32)
    cv2.fillPoly(mask, [roi], 255)

    # Remove vehicle areas from ROI
    for (vx1, vy1, vx2, vy2) in vehicle_boxes:
        cv2.rectangle(mask, (vx1, vy1), (vx2, vy2), 0, thickness=-1)

    masked_edges = cv2.bitwise_and(edges, mask)

    # Detect lines
    lines = cv2.HoughLinesP(masked_edges, 1, np.pi / 180, 30, minLineLength=30, maxLineGap=100)
    lane_overlay = np.zeros_like(frame)
    left_lane_points = []
    right_lane_points = []

    # Classify lines based on slope
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            slope = (y2 - y1) / (x2 - x1 + 1e-6)
            if abs(slope) > 0.3:
                if slope < 0:
                    left_lane_points.extend([(x1, y1), (x2, y2)])
                else:
                    right_lane_points.extend([(x1, y1), (x2, y2)])

    def fit_lane(points, degree=2):
        """
        Fits a polynomial lane line using RANSAC to reduce outlier influence.
        """
        if len(points) > 10:
            points = np.array(points)
            y_vals = points[:, 1].reshape(-1, 1)
            x_vals = points[:, 0]
            ransac = RANSACRegressor()
            ransac.fit(y_vals, x_vals)
            return np.polyfit(y_vals.flatten(), ransac.predict(y_vals), degree)
        return None

    # Fit lane lines
    left_fit = fit_lane(left_lane_points)
    right_fit = fit_lane(right_lane_points)
    lane_centre_fit = previous_lane_centre_fit

    # Estimate lane centre line
    if left_fit is not None and right_fit is not None:
        lane_centre_fit = (left_fit + right_fit) / 2
    elif previous_lane_centre_fit is not None:
        lane_centre_fit = previous_lane_centre_fit
    elif right_fit is not None:
        lane_centre_fit = right_fit - np.array([0, width // 4, 0])
    elif left_fit is not None:
        lane_centre_fit = left_fit + np.array([0, width // 3, 0])
    else:
        lane_centre_fit = None

    # Smooth lane centre line with previous estimate
    if previous_lane_centre_fit is not None and lane_centre_fit is not None and (left_fit is not None and right_fit is not None):
        lane_centre_fit = 0.9 * previous_lane_centre_fit + 0.1 * lane_centre_fit

    if lane_centre_fit is not None:
        previous_lane_centre_fit = lane_centre_fit

    # Draw lane lines
    cv2.polylines(lane_overlay, [roi], True, (0, 255, 255), 3)
    for y in range(600, height, 5):
        if left_fit is not None:
            x_left = int(np.polyval(left_fit, y))
            cv2.circle(lane_overlay, (x_left, y), 3, (255, 0, 0), -1)
        if right_fit is not None:
            x_right = int(np.polyval(right_fit, y))
            cv2.circle(lane_overlay, (x_right, y), 3, (0, 0, 255), -1)
        if lane_centre_fit is not None:
            x_centre = int(np.polyval(lane_centre_fit, y))
            cv2.circle(lane_overlay, (x_centre, y), 3, (0, 255, 0), -1)

    return lane_overlay, lane_centre_fit

def process_frame(frame, frame_count):
    """
    Processes a single video frame:
    - Detects objects and lane lines
    - Tracks vehicles and computes lateral motion
    - Triggers alerts for distracted or impaired driving
    """
    height, width = frame.shape[:2]
    cv2.putText(frame, f"Frame: {frame_count}", (1150, 790),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
    bottom_limit = 0.8 * height
    roi = np.array([[(400, 800), (850, 560), (1000, 560), (1380, 800)]], dtype=np.int32)

    lane_overlay, lane_centre_fit = detect_lanes(frame, [])
    results = model.predict(source=frame, stream=True)

    global object_tracks, next_object_id
    if 'next_object_id' not in globals():
        next_object_id = 0

    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cls_id = int(box.cls[0])
            if cls_id not in classes_of_interest:
                continue

            # Compute object centre
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
            if cy > bottom_limit:
                continue

            in_roi = cv2.pointPolygonTest(roi, (cx, cy), False) >= 0

            matched_id = None
            for obj_id, track in object_tracks.items():
                if track['cls_id'] == cls_id:
                    prev_centre = track['centre']
                    dist = np.hypot(cx - prev_centre[0], cy - prev_centre[1])
                    if dist < 50:
                        matched_id = obj_id
                        break

            if matched_id is None:
                matched_id = next_object_id
                next_object_id += 1
                object_tracks[matched_id] = {
                    'cls_id': cls_id,
                    'centre': (cx, cy),
                    'lateral_history': deque(maxlen=LATERAL_HISTORY_LENGTH),
                    'ave_lateral_history': deque(maxlen=LATERAL_HISTORY_LENGTH),
                    'area_history': deque(maxlen=5),
                    'sign_change_latch': 0,
                    'last_sign': None
                }

            track = object_tracks[matched_id]
            lateral_disp = track['centre'][0] - cx
            track['lateral_history'].append(lateral_disp)
            track['centre'] = (cx, cy)

            avg_lateral = np.mean(track['lateral_history']) if track['lateral_history'] else 0
            track['ave_lateral_history'].append(avg_lateral)

            # Detect sign changes in lateral movement
            current_sign = np.sign(avg_lateral)
            if track['last_sign'] is not None and current_sign != 0 and current_sign != track['last_sign']:
                track['sign_change_latch'] += 1
            elif len(track['ave_lateral_history']) == LATERAL_HISTORY_LENGTH:
                signs = [np.sign(val) for val in track['ave_lateral_history']]
                if all(s == signs[0] for s in signs):
                    track['sign_change_latch'] = 0

            if current_sign != 0:
                track['last_sign'] = current_sign

            # Calculate deviation from lane centre
            if lane_centre_fit is not None:
                lane_centre_x = int(np.polyval(lane_centre_fit, cy))
                off_centre = abs(cx - lane_centre_x)
                cv2.circle(frame, (lane_centre_x, cy), 5, (0, 255, 0), -1)
            else:
                off_centre = 0

            # Track size history to estimate movement direction
            current_area = (x2 - x1) * (y2 - y1)
            track['area_history'].append(current_area)
            if len(track['area_history']) == 5:
                diffs = np.diff(track['area_history'])
                if all(d > 0 for d in diffs):
                    direction = "Approaching"
                elif all(d < 0 for d in diffs):
                    direction = "Receding"
                else:
                    direction = "Steady"
            else:
                direction = "Steady"

            # Raise alerts
            alarms = []
            if in_roi:
                if abs(avg_lateral) > LATERAL_MOVEMENT_THRESHOLD and off_centre > OFF_CENTRE_THRESHOLD:
                    alarms.append("DISTRACTED DRIVER AHEAD")
                if track['sign_change_latch'] >= SIGN_CHANGE_LATCH_THRESHOLD:
                    alarms.append("IMPAIRED DRIVER AHEAD")

            colour = (0, 0, 255) if alarms else (255, 0, 0)
            cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)
            cv2.circle(frame, (cx, cy), 5, (0, 255, 255), -1)

            y_text = y2 + 20
            for text in [
                f"Class: {classes_of_interest[cls_id]}",
                f"AvgLateral: {avg_lateral:.2f}",
                f"OffCentre: {off_centre}",
                f"Direction: {direction}"
            ]:
                cv2.putText(frame, text, (x1, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
                y_text += 15

            
            for alarm in alarms:
                cv2.putText(frame, alarm, (x1, y_text), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
                y_text += 15

            y_text += 10  # Gap before alarms

            # Optional: Display lateral movement history
            if in_roi:
                sign_changes = track['sign_change_latch']
                if sign_changes == 0:
                    text_colour = (255, 0, 0)
                elif sign_changes == 1:
                    text_colour = (0, 255, 0)
                elif sign_changes == 2:
                    text_colour = (0, 255, 255)
                elif sign_changes >= 3:
                    text_colour = (0, 0, 255)
                else:
                    text_colour = (255, 0, 0)

                for i, avg_lat in enumerate(reversed(track['ave_lateral_history'])):
                    cv2.putText(frame, f"AvgLat {20 - i}: {avg_lat:.2f}", (x1, y_text),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_colour, 1)
                    y_text += 15

    return cv2.addWeighted(frame, 0.8, lane_overlay, 0.4, 0)

def process_video(input_video, output_video):
    """
    Processes an input video frame-by-frame and saves annotated output to a file.
    """
    global next_object_id
    next_object_id = 0

    cap = cv2.VideoCapture(input_video)
    if not cap.isOpened():
        print("Error opening video file")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))

    frame_count = 0
    csv_data = []  # Initialize list to store CSV rows

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        output_frame = process_frame(frame, frame_count)
        out.write(output_frame)

        # Collect data per object in the current frame
        for obj_id, track in object_tracks.items():
            cx, cy = track['centre']
            cls_id = track['cls_id']
            avg_lateral = np.mean(track['lateral_history']) if track['lateral_history'] else 0
            lane_centre_x = int(
                np.polyval(previous_lane_centre_fit, cy)) if previous_lane_centre_fit is not None else cx
            off_centre = abs(cx - lane_centre_x)

            # Define the same ROI polygon
            roi_polygon = np.array([[400, 800], [850, 560], [1000, 560], [1380, 800]], np.int32)
            in_roi = cv2.pointPolygonTest(roi_polygon, (cx, cy), False) >= 0

            # Skip logging if object not in ROI
            if not in_roi:
                continue

            alarms = []
            impaired_logged = False

            if abs(avg_lateral) > LATERAL_MOVEMENT_THRESHOLD and off_centre > OFF_CENTRE_THRESHOLD:
                alarms.append("DISTRACTED DRIVER AHEAD")
            if track['sign_change_latch'] >= SIGN_CHANGE_LATCH_THRESHOLD:
                alarms.append("IMPAIRED DRIVER AHEAD")
                impaired_logged = True

            direction = "Unknown"
            if len(track['area_history']) == 5:
                diffs = np.diff(track['area_history'])
                if all(d > 0 for d in diffs):
                    direction = "Approaching"
                elif all(d < 0 for d in diffs):
                    direction = "Receding"
                else:
                    direction = "Steady"

            csv_data.append([
                frame_count,
                obj_id,
                classes_of_interest.get(cls_id, "Unknown"),
                cx,
                cy,
                f"{avg_lateral:.2f}",
                off_centre,
                direction,
                track['sign_change_latch'],
                ";".join(alarms),
                "SIGN CHANGE BEFORE ALARM" if impaired_logged else ""
            ])

        frame_count += 1
        cv2.imshow("Final Output", output_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Write the collected data to CSV
    with open("driver_alerts_log.csv", mode="w", newline='') as file:
        writer = csv.writer(file)
        writer.writerow([
            "Frame", "ObjectID", "Class", "CX", "CY",
            "AvgLateral", "OffCentre", "Direction",
            "SignChangeLatch", "Alarms", "SignChangeInfo"
        ])

        writer.writerows(csv_data)

    print("CSV file saved as: driver_alerts_log.csv")

    cap.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    process_video('GRMN0025.MP4', 'final_output.avi')

    
